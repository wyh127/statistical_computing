---
title: "Lab 2 Solutions"
author: "Enter Your Name and UNI Here"
output: pdf_document
---


```{r, echo = FALSE}
set.seed(1) # Please don't remove this code!
```

# Instructions 
Before you leave lab today make sure that you upload a knitted HTML or pdf file to the canvas page (this should have a .html or .pdf extension).  No need to upload the .Rmd file.

# Part (A): Simple Linear Regression Model

1) Import the **diamonds.csv** dataset into R and store in a dataframe called **diamonds**.  Use the **lm()** command to regress **price** (response) on **carat** (predictor) and save this result as **lm0**.  What are the coefficients of **lm0**?
 

```{r}
setwd("~/Desktop/Data/")
diamonds <- read.csv("diamonds_small.csv", as.is = TRUE, header = TRUE)
rows       <- dim(diamonds)[1]
diamonds <- diamonds[sample(1:rows, 2000), ]
lm0 <- lm(price ~ carat, data = diamonds)
coefficients(lm0)
```

Recall from lecture that the estimates $\hat{\beta}_0$ and $\hat{\beta}_1$ that you just calculated with **lm()** are functions of the data values and are therefore themselves are random (they inherit variability from the data).  If we were to recollect the diamonds data over and over again, the estimates would be different each time.

In this lab we'll use bootstrapping to answer the following questions:
\begin{enumerate}
\item \textbf{``How much does $\hat{\beta}_1$ vary from one replication of the experiment to the other?"}
\item \textbf{``What are all the values of $\beta_1$ that would have produced this data with high probability?"}
\end{enumerate}

## Part (B): How Does $\hat{\beta}_1$ Vary?

Strategy:  we'll re-sample **(price, carat)** pairs in order to provide an estimate for how $\hat{\beta}_1$ varies across samples.

1) How many rows are in the **diamonds** dataset?  Call this value **n**.

```{r}
n <- nrow(diamonds)
n
```

2) We'll next use the **sample()** function to re-sample **n** rows of the **diamonds** dataset *with replacement*.  The following code provides a single re-sample of the values $1, 2, \ldots, n$, or a single re-sample of the rows of the dataset.

```{r}
resample1 <- sample(1:n, n, replace = TRUE)
```

Now write a loop to calculate **B <- 1000** such re-samples and store them as rows of the matrix **resampled_values**.

```{r}
B <- 1000
resampled_values <- matrix(NA, nrow = B, ncol = n)
for (b in 1:B) {
  resampled_values[b, ] <- sample(1:n, n, replace = TRUE)
}
```

3) Now we'll use each re-sampled dataset to provide a new estimate of $\hat{\beta}_1$.  Write a line of code that uses **resample1** above to produce a resamples dataset of **(price, carat)** pairs.  Using the re-sampled dataset, use **lm()** to produce new estimates of $\hat{\beta}_0$ and $\hat{\beta}_1$.  These values should be stored in a vector called **resample1_ests**.

```{r}
resample1_ests <- coefficients(lm(price ~ carat, data = diamonds[resample1, ]))
resample1_ests
```

4) Repeat the above call for each re-sampled dataset produced from the **resampled_values** matrix.  We'll store the new coefficient estimates in a matrix **resampled_ests** with **B** rows and **2** columns.  Again you'll want to write a loop, this time that iterates over the rows of **resampled_values**.  (Note that if you are very clever this could be done using **apply()**.)  Make sure to print **head(resample_ests)** at the end.

Loop:

```{r}
resampled_ests <- matrix(NA, nrow = B, ncol = 2)
colnames(resampled_ests) <- c("Intercept_Est", "Slope_Est")
for (b in 1:B) {
  resampled_rows       <- resampled_values[b, ]
  resampled_data       <- diamonds[resampled_rows, ]
  resampled_ests[b, ] <- coefficients(lm(price ~ carat, data = resampled_data))
}
head(resampled_ests)
```


Apply function: 
```{r}
my.boot.coef <- function(x) {
  return(coefficients(lm(price ~ carat, data = diamonds[x,])))
}
resampled_ests.2 <- apply(resampled_values,1,my.boot.coef)
head(t(resampled_ests.2))
```




5) Recall from lecture that $\left(\hat{\beta}_1^{(b)}\right)_{b=1}^B - \hat{\beta}_1$ approximates the sampling distribution of $\hat{\beta}_1 - \beta_1$ where $\beta_1$ is the population parameter, $\hat{\beta}_1$ is the estimate from out original dataset, and $\left(\hat{\beta}_1^{(b)}\right)_{b=1}^B$ are the $B$ bootstrap estimates.  

Make a vector **diff_estimates** that holds the differences between the original estimate of $\hat{\beta}_1$ from **lm0** and the bootstrap estimates (they're in the `Slope_Est' column).  It should have length **B**.

```{r}
diff_estimates <- coefficients(lm0)[2] - resampled_ests[, "Slope_Est"]
```

6) Plot a histogram of the estimates of differences given in **diff_estimates**.  Label the x-axis appropriately.

```{r}
hist(diff_estimates, xlab = "Original - Resampled Slope Estimates", main = "Bootstrap Resamples")
```

6) Calculate the variance of the bootstrap estimates of $\hat{\beta}_1$.

```{r}
sd(resampled_ests[, "Slope_Est"])
```


# [Optional] Part (C): Bootstrap Confidence Intervals

Note: This section is optional.  If you get the chance to do it during lab, great, but it's not necessary that this part is completed when you turn in the lab.

Finally we'd like to approximate confidence intervals for the regression coefficients.  Recall that a confidence interval is a random interval which contains the truth with high
probability (the confidence level). If the confidence interval for $\beta_1$ is C, and the confidence level is $1-\alpha$, then we want 
\[Pf(\beta_1 \in C) = 1-\alpha\]
no matter what the true value of $\beta_1$. 

We estimate the confidence interval from the bootstrap estimates by finding a range of $\left(\hat{\beta}_1^{(b)}\right)_{b=1}^B - \hat{\beta}_1$ which holds $1-\alpha$ percent of the values.  In our case, let $\alpha = 0.05$, so we estmiate a confidence interval with level $0.95$.

(1) Let **Cu** and **Cl** be the upper and lower limits of the confidence interval.  Use the **quantile()** function to find the $0.025$ and $0.975$ quantiles of the vector **diff_estimates** calculated in B(5).  Then **Cu** is the sum of the original estimate of $\hat{\beta}_1$ from **lm0** with the upper quantile and **Cl** is the sum of the original estimate of $\hat{\beta}_1$ from **lm0** with the lower quantile.

Basic bootstrap interval: 
```{r}
Cl <- 2*coefficients(lm0)[2] - quantile(resampled_ests[, "Slope_Est"], 0.975)
Cu <- 2*coefficients(lm0)[2] - quantile(resampled_ests[, "Slope_Est"], 0.025)
int <- c(Cl, Cu)
int
```

(2) Instead if traditional  bootstrap intervals, construct **percentile** based bootstrap intervals.  Use the **quantile()** function to find the $0.025$ and $0.975$ quantiles of the vector **resampled_ests[, "Slope_Est"]** calculated in B(4).  

```{r}
Cl <- quantile(resampled_ests[, "Slope_Est"], 0.025)
Cu <- quantile(resampled_ests[, "Slope_Est"], 0.975)
int <- c(Cl, Cu)
int
```

