---
title: "GU4206-GR5206 Final Exam [100 pts]"
author: "Yuhao Wang (yw3204)"
date: "May 4th, 2018"
output: pdf_document
---



The STAT Spring 2018 GU4206-GR5206 Final Exam is open notes, open book(s), open computer and online resources are allowed.  Students are **not** allowed to communicate with any other people regarding the final with the exception of the instructor (Gabriel Young) and TA (Fan Gao).  This includes emailing fellow students, using WeChat and other similar forms of communication.  If there is any suspicious of students cheating, further investigation will take place.  If students do not follow the guidelines, they will receive a zero on the exam and potentially face more severe consequences.  The exam will be posted on Canvas at 9:00AM.  Students are required to submit both the .pdf and .Rmd files on Canvas (or .html if you must) by 12:00PM. Late exams will not be accepted. If for some reason you are unable to upload the completed exam on Canvas by 12:00PM, them immediately email the markdown file to the course TA.           


# Part 1: Simulation [40 pts]  

In this section, we consider a **mixture** of two normal distributions.  Here we assume that our random variable is governed by the probability density $f(x)$, defined by
\begin{align*}
f(x)&=f(x;\mu_1,\sigma_1,\mu_2,\sigma_2,\delta)\\
&=\delta f_1(x;\mu_1,\sigma_1)+(1-\delta)f_2(x;\mu_2,\sigma_2)\\
 &=\delta \frac{1}{\sqrt{2 \pi \sigma_1^2}}\exp{-\frac{1}{2\sigma_1^2}(x-\mu_1)^2}+(1-\delta) \frac{1}{\sqrt{2 \pi \sigma_2^2}}\exp{-\frac{1}{2\sigma_2^2}(x-\mu_2)^2}, 
\end{align*}
where  $-\infty<x<\infty$ and the parameter space is defined by $-\infty < \mu_1,\mu_2 <\infty$, $\sigma_1,\sigma_2 >0$, and $0\leq\delta\leq1$.   The **mixture parameter** $\delta$ governs how much mass gets placed on the first distribution $f(x;\mu_1,\sigma_1)$ and the complement of $\delta$ governs how much mass gets placed on the other distribution $f_2(x;\mu_2,\sigma_2)$.  

In our setting, suppose that we are simulating $n=10,000$ heights from the population of both males and females.  Assume that males are distributed normal with mean $\mu_1=70\text{[in]}$ and standard deviation $\sigma_1=3\text{[in]}$ and females are distributed normal with mean $\mu_2=64\text{[in]}$ and standard deviation $\sigma_2=2.5\text{[in]}$.  Also assume that each distribution contributes equal mass, i.e., set the mixture parameter to $\delta=.5$.  The distribution of males is governed by 
\[
f_1(x;\mu_1,\sigma_1)=\frac{1}{\sqrt{2 \pi \sigma_1^2}}\exp{-\frac{1}{2\sigma_1^2}(x-\mu_1)^2}, \ \ \ -\infty<x<\infty,
\]
and the distribution of females is governed by
\[
f_2(x;\mu_2,\sigma_2)=\frac{1}{\sqrt{2 \pi \sigma_2^2}}\exp{-\frac{1}{2\sigma_2^2}(x-\mu_2)^2}, \ \ \ -\infty<x<\infty.
\]
The goal is to **simulate** from the **mixture distribution** 
\[
\delta f_1(x;\mu_1,\sigma_1)+(1-\delta)f_2(x;\mu_2,\sigma_2),
\]
where $\mu_1=70,\sigma_1=3,\mu_2=64,\sigma_2=2.5,\delta=2.5$ using the accept-reject algorithm. 

## Perform the following tasks:

1) [10 pts]   Using **ggplot**, graph $f_1(x;\mu_1,\sigma_1)$, $f_2(x;\mu_2,\sigma_2)$ and the mixture $f(x)$ all on the same plot. Make sure the plot includes a legend and is labeled appropriately.    

```{r}
# Solution goes here 
library("ggplot2")

f1 <- function(x, mu1 = 70, sigma1 = 3) {
  return(1/(sqrt(2*pi)*sigma1) * exp(-1/(2*sigma1^2) * (x-mu1)^2))
}

f2 <- function(x, mu2 = 64, sigma2 = 2.5) {
  return(1/(sqrt(2*pi)*sigma2) * exp(-1/(2*sigma2^2) * (x-mu2)^2))
}

f3 <- function(x, delta=0.5) {
  return(delta*f1(x) + (1-delta)*f2(x))
}

del <- 0.5
rg <- seq(60, 80, 0.01)
ggplot() + geom_line(aes(x = rg, y = dnorm(rg, 70, 3), color = "1")) + 
  geom_line(aes(x = rg, y = dnorm(rg, 65, 2.5), color = "2")) +
  geom_line(aes(x = rg, y = del*dnorm(rg, 70, 3) + (1-del)*dnorm(rg, 65, 2.5), color = "3")) +
  labs(y = "density", title="normals", color = "functions")


x_range <- seq(60, 80, 0.01)
df <- data.frame(x = x_range, y1 = f1(x_range), y2 = f2(x_range), y3 = f3(x_range))
ggplot(data = df) + geom_line(aes(x = x, y = y1, col = "f1")) +
  geom_line(aes(x = x, y = y2, col = "f2")) + 
  geom_line(aes(x = x, y = y3, col = "f3")) + 
  labs(y = "density", color = "functions")
```

2) [25 pts] Use the **accept-reject** algorithm to simulate from this mixture distribution.  To receive full credit:
\begin{itemize}
\item[2.i] Clearly identify an \textbf{easy to simulate} distribution $g(x)$.  I recommend picking a normal distribution or a Cauchy distribution for $g(x)$. 
\item[2.ii] Identify a \textbf{suitable} value of $alpha$ such that your envelope function $e(x)$ satisfies
\[
f(x) \leq e(x) = g(x)/\alpha, \ \ \text{where} \ \ 0<\alpha<1.
\]
Note that you must choose $\alpha$ so that $e(x)$ is close to $f(x)$.  Show that your $alpha$ is \textbf{suitable} using a plot.
\item[2.iii] Simulate 10,000 draws from the mixture distribution using the \textbf{accept-reject} algorithm.  Display the first 20 simulated values.  Also, using \textbf{ggplot} or \textbf{base R}, construct a histogram of the simulated mixture distribution with the true mixture pdf $f(x)$ overlayed on the plot.
\end{itemize}

2.i) [5 pts]  

```{r}
# Solution goes here 
g <- function(x, mu = 67, sigma = 4) {
  return(1/(sqrt(2*pi)*sigma) * exp(-1/(2*sigma^2) * (x-mu)^2))
}
```

2.ii) [10 pts]  By inspection, we see that choosing $\alpha=.44$ allows $e(x)$ to be greater than $f(x)$ for all $x$ and the envelope sits relatively close to the target distribution.

```{r}
# Solution goes here 
alpha <- 0.4
xr <- seq(50, 80, 0.01)
plot(xr, g(xr)/alpha, type = "l", col = "red")
lines(xr, y = f3(xr))
legend(50, 0.2, c("g", "f3"), col = c("red", "black"), pch = c(19, 19))
```

2.iii) [10 pts] The **Accept-Reject** algorithm is coded below: 

```{r}
# Solution goes here 
simu <- c()
i <- 0
while(i < 10000) {
  x <- rnorm(1, 67, 4)
  y <- runif(1)
  if(g(x)/alpha*y < f3(x)) {
    simu <- c(simu, x)
    i <- i+1
  }
}

head(simu, 20)
```

Plot: 

```{r}
# Solution goes here 
hist(simu, probability = T)
lines(seq(55, 85, 0.01), f3(seq(55, 85, 0.01)), col = "red")
```

3) [5 pts] Slightly change the **Accept-Reject** algorithm from Part (2.iii) to also include the acceptance rate, i.e., how many times did the algorithm accept a draw compared to the total number of trials performed.  What proportion of cases were accepted?  Compare this number to your chosen $\alpha$ and comment on the result.

```{r}
# Solution goes here 
simu1 <- c()
j <- 1
k <- 1
while(k <= 10000) {
  x <- rnorm(1, 67, 4)
  y <- runif(1)
  if(g(x)/alpha*y < f3(x)) {
    simu1 <- c(simu, x)
    k <- k+1
  }
  else {
    j <- j+1
  }
}

j/(j+k)
```

# Part II: Maximum Likelihood Estimaiton and Newton's Method [25 pts] 

Recall in logistic regression, the likelihood function is derived by **linking** the mean of $Y_i$ with a linear function.

**Logistic Regression Model:**

Let $Y_1,Y_2,\ldots,Y_n$ be independently distributed Bernoulli random variables with respective success probabilities $p_1,p_2,\ldots,p_n$.  Then the **logistic regression model** is: 
\[
E[Y_i]=p_i=\frac{e^{(\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\cdots+\beta_px_{i,p})}}{1+e^{(\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\cdots+\beta_px_{i,p})}}, \ \ \ \, i=1,2,\ldots,n.
\]

Notice with some simple algebra, the above model can be expresses as:

\[
\log \bigg{(} \frac{p_i}{1-p_i}\bigg{)}=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\cdots+\beta_px_{i,p} x_i, \ \ \ \, i=1,2,\ldots,n.
\]
The main idea is to **link** the expected value of $Y_i$ ($E[Y_i]=p_i$) to a linear function. This same principle can be applied to other settings. 

## Data Description

Consider a geriatrics experiment designed as a prospective study to investigate the effects of two interventions on the frequency of falls. One hundred subjects were randomly assigned to one of the two interventions: education only ($X_1 = 0$) and education plus aerobic exercise training ($X_1 = 1$). Subjects were at least 65 years of age and in reasonably good health. Three variables considered to be important as control variables were gender ($X_2:0=$female, 1=male), a balance index ($X_3$), and a strength index ($X_4$). The higher the balance index, the more stable the subject: and the higher the strength index, the stronger the subject. Let $Y$ be the number of falls during the six month study.

```{r}
glm.data <- read.table("CH14PR39.txt")
names(glm.data) <- c("Y","X1","X2","X3","X4")
head(glm.data)
```

In this setting, the response variable takes on discrete count values, therefore it is reasonable to assume $Y_1,Y_2,\ldots,Y_{100}$ are independent Poisson random variables with mean $E[Y_i]=\lambda_i$.  Here we can choose a link function that relates $\lambda_i$ to the linear function $\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\beta_3x_{i3}+\beta_4x_{i4}$.  

**Perform the follwoing task:**

4) [25 pts] Assume $Y_1,Y_2,\ldots,Y_{100}$ are independent Poisson random variables with mean
\[
E[Y_i]=\lambda_i=\exp{(\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\beta_3x_{i3}+\beta_4x_{i4})}
\]
Note that the link function is $exp(u)$.  Use maximum likelihood estimation to estimate the Poisson regression model.  To receive full credit:

\begin{itemize}
\item[4.i] Define the negative log-likelihood function in R.  Name the function \textbf{pois.neg.ll}.
\item[4.ii] Test the negative log-likelihood function at the parameter point \textbf{rep(0,5)}.
\item[4.iii] Use the \textbf{Newton's Method} or \textbf{Gradient Descent} algorithm from class to estimate coefficients $\beta_0,\beta_1,\beta_2,\beta_3,\beta_4$. Display the estimated parameters and the number of iterations the algorithm took to converge.  For partial credit, you can use \textbf{nlm()}.      
\end{itemize}

4.i) [10 pts]  
```{r}
# Solution goes here 
pois.neg.ll <- function(beta, y = glm.data[, 1], X=cbind(rep(1, nrow(glm.data)), glm.data[, c(2:5)])) {
  X <- as.matrix(X)
  tmp <- X %*% beta
  term1 <- sum(y * tmp)
  term2 <- sum(exp(tmp))
  return(term2-term1)
}

pois.neg.ll1 <- function(beta, y = glm.data[, 1], X=cbind(rep(1, nrow(glm.data)), glm.data[, c(2:5)])) {
  
  lin_term <- as.matrix(X) %*% beta
  l <- exp(lin_term)
  return(-sum(dpois(y, lambda = l, log = T)))
}

```

4.ii) [5 pts]  

```{r}
# Solution goes here 
pois.neg.ll(rep(0, 5))

pois.neg.ll1(rep(0, 5))
```

4.iii) [10 pts]   
```{r}
# Solution goes here 
nlm(pois.neg.ll, rep(0, 5))

nlm(pois.neg.ll1, rep(0, 5))

library(numDeriv)
Newton.method <- function(f, x0, max.iter = 200, stopping.deriv = 0.001, ...) {
  
  n <- length(x0)
  xmat <- matrix(0, nrow = n, ncol = max.iter)
  xmat[,1] <- x0
  
  for (k in 2:max.iter) {
    # Calculate the gradient
    grad.cur <- grad(f, xmat[ ,k-1], ...) 
    
    # Calculate the hessian
    hess.cur <- hessian(f, xmat[ ,k-1], ...)
    
    # Should we stop?
    if (all(abs(grad.cur) < stopping.deriv)) {
      k <- k-1; break
    }
    
    # Move in the opposite direction of the grad
    xmat[ ,k] <- xmat[ ,k-1] - solve(hess.cur)%*%grad.cur
  }
  
  xmat <- xmat[ ,1:k] # Trim
  return(list(x = xmat[,k],
              xmat = xmat, 
              k = k, 
              minimum=f(xmat[,k],...)
          )
  )
}

Newton.method(pois.neg.ll1, rep(0, 5))
```

Check the result with **glm()** (optional)

```{r}
glm(Y~X1+X2+X3+X4,data=glm.data,family="poisson")
```


# Part III: Cross Validadtion and Linear Regression [35 pts] 

The goal of this section is to illustrate how the **degree** of a polynomial model can be thought of as a tuning parameter.  

**Perform the follwoing task:**


5) [5 pts] Upload the dataset **finalexamtrain.csv** and plot $Y$ versus $x$ using **ggplot**.  Change the points to blue in the plot.   

```{r}
# Solution goes here 
train <- read.csv("finalexamtrain.csv")

ggplot(train) + geom_point(aes(x = x, y = Y), col = "blue")
```

6) [5 pts] In this setting, we regress the response variable $Y$ against a single predictor $x$ using five different models:

**Linear Model: degree=1**
\[
Y_i=\beta_0+\beta_0 x_i+\epsilon_i, \ \ \epsilon_i \sim N(0,\sigma^2) 
\]
**Quadratic Model: degree=2**
\[
Y_i=\beta_0+\beta_1 x_i+\beta_2 x_i^2+\epsilon_i, \ \ \epsilon_i \sim N(0,\sigma^2) 
\]
**Cubic Model: degree=3**
\[
Y_i=\beta_0+\beta_1 x_i+\beta_2 x_i^2+\beta_3 x_i^3+\epsilon_i, \ \ \epsilon_i \sim N(0,\sigma^2) 
\]
**Quartic Model: degree=4**
\[
Y_i=\beta_0+\beta_1 x_i+\beta_2 x_i^2+\beta_3 x_i^3+\beta_4 x_i^4+\epsilon_i, \ \ \epsilon_i \sim N(0,\sigma^2) 
\]
**Quintic Model: degree=5**
\[
Y_i=\beta_0+\beta_1 x_i+\beta_2 x_i^2+\beta_3 x_i^3+\beta_4 x_i^4+\beta_5 x_i^5+\epsilon_i, \ \ \epsilon_i \sim N(0,\sigma^2)
\]

Fit each model using the training data.  To make your life easier, I recommend using the Inhibit Interpretation function **I()**.  Display the estimated coefficients for each model.   

```{r}
# Solution goes here 
lm1 <- lm(Y ~ x, train)
lm2 <- lm(Y ~ x + I(x^2), train)
lm3 <- lm(Y ~ x + I(x^2) + I(x^3), train)
lm4 <- lm(Y ~ x + I(x^2) + I(x^3) + I(x^4), train)
lm5 <- lm(Y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5), train)
```

7)  [10 pts]  Consider the dataframe **finalexamtest.csv** that contains four validation (test) sets each consisting of 50 cases.  Notice that the variable **ValSet** contains four levels.  More specifically, the first 50 cases belong to **TestSet1**, the next 50 cases belong to **TestSet2**, ...etc.   
```{r}
data.test <- read.csv("finalexamtest.csv")
head(data.test)
tail(data.test)
levels(data.test$ValSet)
```

Write a function named **test.error** that inputs a dataframe and outputs the **test error** for each model.  The function should give four predictions errors corresponding to each model, i.e., linear, quadratic, cubic, quartic, and quintic. Note that you are still using the trained models from Part (6).  You are allowed to hard code some of this function.  Test the **test.error* function on the full training data. 

**Hint: y.test <- predict(model,newdata = data.test["x"])**

```{r}
# Solution goes here 
test.error <- function(df) {
  y.test1 <- predict(lm1, newdata = df["x"])
  pred_err1 <- apply((y.test1 - df["Y"])^2, 2, mean)
  
  y.test2 <- predict(lm2, newdata = df["x"])
  pred_err2 <- apply((y.test2 - df["Y"])^2, 2, mean)
  
  y.test3 <- predict(lm3, newdata = df["x"])
  pred_err3 <- apply((y.test3 - df["Y"])^2, 2, mean)
  
  y.test4 <- predict(lm4, newdata = df["x"])
  pred_err4 <- apply((y.test4 - df["Y"])^2, 2, mean)
  
  y.test5 <- predict(lm5, newdata = df["x"])
  pred_err5 <- apply((y.test5 - df["Y"])^2, 2, mean)
  
  # y.test2 <- predict(mod, newdata = df[df$ValSet == "TestSet2", ]["x"])
  # pred_err2 <- apply((y.test2 - data.test[data.test$ValSet == "TestSet2", ]["Y"])^2, 2, mean)
  # 
  # y.test3 <- predict(mod, newdata = df[df$ValSet == "TestSet3", ]["x"])
  # pred_err3 <- apply((y.test3 - data.test[data.test$ValSet == "TestSet3", ]["Y"])^2, 2, mean)
  # 
  # y.test4 <- predict(mod, newdata = df[df$ValSet == "TestSet4", ]["x"])
  # pred_err4 <- apply((y.test4 - data.test[data.test$ValSet == "TestSet4", ]["Y"])^2, 2, mean)
  
  return(c(pred_err1, pred_err2, pred_err3, pred_err4, pred_err5))
}

test.error(train)
```

8) [10 pts] Use the **Split/Apply/Combine** model to compute the test error for each test set: **TestSet1**, **TestSet2**, **TestSet3**, **TestSet4**. You can exhaustively perform this task for partial credit.  Display the test errors for each test set and each model.  Also display the average test error over each validation set.    

```{r}
# Solution goes here 
library("plyr")
ddply(data.test, "ValSet", test.error)
```

9) [5 pts] Create a plot (base R or ggplot) showing both the **average test error** and the **training error** as a function of the polynomial's **degree**. Briefly comment on this plot.     

```{r}
# Solution goes here 

ggplot() + geom_line(aes(x=1:5, y = res, color = "test")) +
  geom_point(aes(x=1:5, y = res, color = "test")) +
  geom_line(aes(x = 1:5, y = test.error(train), color = "train")) +
  geom_point(aes(x = 1:5, y = test.error(train), color = "train"))
  labs(y = "error", color = "error")


res <- ddply(data.test, "ValSet", test.error)
res <- apply(res[2:6], 2, mean)

plot(1:5, res, type = "l", ylim = c(2000, 3600), ylab = "error", xlab = "degree")
lines(1:5, test.error(train))
```

y1 <- c(0.7, -1.0, -0.2, -1.2, -0.1, 3.4, 0, 0.8, 3.7, 2)



