---
title: "hw7_yw3204"
author: "wyh"
date: "11/25/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## i.
```{r}
poisLoglik <- function(l, data) {
  num <- (l ** data) * exp(-l)
  deno <- factorial(data)
  ratio <- num / deno
  res <- sum(log(ratio))
  return(res)
}

poisLoglik(1, c(1, 0, 0, 1, 1))
```

## ii.
```{r}
# read data
moretti <- read.csv("moretti.csv")

count_new_genres <- function(year) {
  return(sum(moretti$Begin == year))
}

count_new_genres(1803)
count_new_genres(1850)
```
The values are 0 and 3 seperately.

## iii.
```{r}
new_genres <- c()

for(i in c(1740:1900)) {
  new_genres <- c(new_genres, count_new_genres(i))
}

new_genres[64]
new_genres[111]
```
The positions in the vector correspond to the years 1803 and 1850 are 64 and 111. The values should be 0 and 3 which are exactly what in the corresponding positions in vector new_genres. 

## iv.
```{r}
lambdas <- seq(0.01, 1, 0.01)
logs <- c()
for(l in lambdas) {
  logs <- c(logs, poisLoglik(l, new_genres))
}
plot(lambdas, logs, type = "l", xlab = "lambda", ylab = "log-likelihood")
```

The maximum is reached at around 0.2.

## v.
```{r}
negPoisLoglik <- function(l, data = new_genres) {
  num <- (l ** data) * exp(-l)
  deno <- factorial(data)
  ratio <- num / deno
  res <- sum(log(ratio))
  return(-res)
}

nlm(negPoisLoglik, p = 1)
```
According to the result above, the minimum of the negative log-likelihhod function is reached at around 0.273. Thus, the maximum of the log-likelihhod function is reached at around 0.273.

## vi.
```{r}
# take first order difference
year_lap <- diff(moretti$Begin)

year_lap
mean(year_lap)
sd(year_lap)
coe_var <- sd(year_lap)/mean(year_lap)
coe_var
```

## vii.
### a.
```{r}
cal_interval <- function(vec) {
  inds <- c()
  for(i in c(1:length(vec))) {
    if(vec[i] != 0) {
      inds <- c(inds, rep(i, vec[i]))
    }
  }
  
  intergenre_intervals <- diff(inds)
  return(intergenre_intervals)
}

cal_interval(new_genres)
```

### b.
```{r}
cal_CoeVar <- function(num_ys, lambda) {
  n_genres <- rpois(num_ys, lambda)
  
  intervals <- cal_interval(n_genres)
  
  coe_var <- sd(intervals)/mean(intervals)
  
  return(list(intervals, coe_var))
}

cal_CoeVar(161, 0.273)

# chek the mean
# mean(cal_CoeVar(162, 0.273)[[1]])
```

## viii.
```{r}
coes <- c()

for(i in c(1:10000)) {
  coes <- c(coes, cal_CoeVar(161, 0.273)[[2]])
}

# fraction of simulations having a higher coefficient of variation than Morettiâ€™s data
sum(coes > coe_var) / length(coes)
```

## ix.
The proportion from the last question shows that the coefficient of variation for the moretti's data is relatively higher than that of the supposed Poisson process. That's to say, the appearance of genres is not following a Poisson process. And thus, it doesn't have stationary and independent increment which means genres tend to appear together in burst.







